# Integra√ß√£o OpenAI via MCP (Model Context Protocol) - Documenta√ß√£o Completa

> **üìñ Documenta√ß√£o Oficial**: Este documento √© baseado na documenta√ß√£o oficial da OpenAI dispon√≠vel em: https://platform.openai.com/docs/overview

Este documento explica como usar a API da OpenAI no projeto usando o SDK oficial, incluindo a cria√ß√£o de agentes (Assistants API) lan√ßada recentemente.

## üìö Documenta√ß√£o Oficial da OpenAI

### Acesse a Documenta√ß√£o Completa:

- **Vis√£o Geral**: https://platform.openai.com/docs/overview
- **Assistants API Overview**: https://platform.openai.com/docs/assistants/overview
- **Assistants Quickstart**: https://platform.openai.com/docs/assistants/quickstart
- **API Reference**: https://platform.openai.com/docs/api-reference
- **Models**: https://platform.openai.com/docs/models

### Conte√∫do da Documenta√ß√£o Oficial:

A documenta√ß√£o oficial da OpenAI em https://platform.openai.com/docs/overview cont√©m:

1. **Vis√£o Geral da API**
   - Introdu√ß√£o aos modelos dispon√≠veis
   - Guias de in√≠cio r√°pido
   - Exemplos de c√≥digo
   - Melhores pr√°ticas

2. **Assistants API (Agentes)**
   - Como criar assistentes (agentes)
   - Gerenciamento de threads (conversas)
   - Execu√ß√£o de runs
   - Uso de ferramentas (tools)
   - Code Interpreter
   - File Search
   - Function Calling

3. **Chat Completions**
   - Como fazer chamadas de chat
   - Gerenciamento de mensagens
   - Streaming de respostas
   - Par√¢metros e configura√ß√µes

4. **Modelos Dispon√≠veis**
   - GPT-4 Turbo
   - GPT-4
   - GPT-3.5 Turbo
   - O1 (racioc√≠nio)
   - E outros modelos especializados

5. **Guias e Tutoriais**
   - Text Generation
   - Function Calling
   - Embeddings
   - Fine-tuning
   - Rate Limits
   - Error Handling

## üì¶ Instala√ß√£o

O SDK da OpenAI j√° foi adicionado ao `requirements.txt`:

```txt
openai==1.12.0
```

Para instalar no container Docker:

```bash
docker compose exec api pip install openai==1.12.0
```

Ou reconstruir a imagem:

```bash
docker compose build --no-cache api
docker compose up -d api
```

## üîë Configura√ß√£o

A chave da API deve ser configurada na vari√°vel de ambiente `OPENAI_API_KEY`:

### No arquivo `.env`:

```env
OPENAI_API_KEY=sk-...
```

### No `docker-compose.yml`:

A vari√°vel j√° est√° configurada:

```yaml
environment:
  - OPENAI_API_KEY=${OPENAI_API_KEY:-}
```

## üíª Uso B√°sico - Chat Completions

### Exemplo B√°sico

```python
from openai import OpenAI

# Inicializar cliente
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Fazer uma chamada
response = client.chat.completions.create(
    model="gpt-4-turbo-preview",
    messages=[
        {"role": "system", "content": "Voc√™ √© um assistente √∫til."},
        {"role": "user", "content": "Ol√°, como voc√™ est√°?"}
    ],
    temperature=0.7,
    max_tokens=1000
)

# Extrair resposta
answer = response.choices[0].message.content
print(answer)
```

## ü§ñ Assistants API - Cria√ß√£o de Agentes

> **Documenta√ß√£o Oficial**: https://platform.openai.com/docs/assistants/overview

A Assistants API permite criar agentes aut√¥nomos que podem:
- Manter contexto de conversas atrav√©s de threads
- Usar ferramentas (tools) como code interpreter, file search, function calling
- Processar m√∫ltiplas mensagens em sequ√™ncia
- Executar tarefas complexas de forma aut√¥noma

### 1. Criando um Assistente (Agente)

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/how-it-works/creating-assistants

```python
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # Criar um assistente com GPT-5.1
    assistant = client.beta.assistants.create(
        name="Analisador de Produtos ML",
        instructions="""Voc√™ √© um especialista em an√°lise de produtos do Mercado Livre.
        Sua fun√ß√£o √© analisar produtos, identificar oportunidades de melhoria,
        sugerir otimiza√ß√µes de pre√ßo, SEO e marketing.""",
        model="gpt-5.1",  # GPT-5.1 - melhor para coding e tarefas agentic
        tools=[
            {"type": "code_interpreter"},  # Permite executar c√≥digo Python
            {"type": "file_search"}        # Permite buscar em arquivos
        ],
        # GPT-5 usa reasoning_effort e verbosity ao inv√©s de temperature
        reasoning_effort="medium",  # N√≠vel m√©dio de racioc√≠nio (padr√£o)
        verbosity="medium"  # N√≠vel m√©dio de detalhamento (padr√£o)
    )

print(f"Assistente criado com ID: {assistant.id}")
```

### 2. Criando um Assistente com Fun√ß√µes Customizadas

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/tools/function-calling

```python
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Definir fun√ß√µes que o assistente pode chamar
functions = [
    {
        "type": "function",
        "function": {
            "name": "get_product_price",
            "description": "Busca o pre√ßo atual de um produto no Mercado Livre",
            "parameters": {
                "type": "object",
                "properties": {
                    "product_id": {
                        "type": "string",
                        "description": "ID do produto no ML"
                    }
                },
                "required": ["product_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "update_product_price",
            "description": "Atualiza o pre√ßo de um produto",
            "parameters": {
                "type": "object",
                "properties": {
                    "product_id": {
                        "type": "string",
                        "description": "ID do produto"
                    },
                    "new_price": {
                        "type": "number",
                        "description": "Novo pre√ßo do produto"
                    }
                },
                "required": ["product_id", "new_price"]
            }
        }
    }
]

# Criar assistente com fun√ß√µes usando GPT-5.1
assistant = client.beta.assistants.create(
    name="Gerenciador de Pre√ßos ML",
    instructions="""Voc√™ √© um assistente especializado em gerenciar pre√ßos de produtos.
    Use as fun√ß√µes dispon√≠veis para buscar e atualizar pre√ßos quando solicitado.""",
    model="gpt-5.1",  # GPT-5.1 com melhor precis√£o
    tools=functions,
    # GPT-5 usa reasoning_effort para controlar profundidade do racioc√≠nio
    reasoning_effort="high",  # Alto racioc√≠nio para opera√ß√µes cr√≠ticas
    verbosity="low"  # Respostas concisas para opera√ß√µes precisas
)
```

### 3. Usando um Assistente em uma Thread (Conversa)

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages

A Assistants API mant√©m mem√≥ria automaticamente atrav√©s das threads. Cada thread preserva todo o hist√≥rico de mensagens, permitindo conversas contextuais.

```python
from openai import OpenAI
import time

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1. Criar uma thread (conversa)
thread = client.beta.threads.create()

# 2. Adicionar mensagem √† thread
message = client.beta.threads.messages.create(
    thread_id=thread.id,
    role="user",
    content="Analise o produto MLB123456789 e sugira melhorias de pre√ßo e SEO"
)

# 3. Executar o assistente na thread
run = client.beta.threads.runs.create(
    thread_id=thread.id,
    assistant_id=assistant.id
)

# 4. Aguardar conclus√£o (polling)
while run.status in ['queued', 'in_progress', 'cancelling']:
    time.sleep(1)
    run = client.beta.threads.runs.retrieve(
        thread_id=thread.id,
        run_id=run.id
    )

# 5. Obter resposta
if run.status == 'completed':
    messages = client.beta.threads.messages.list(thread_id=thread.id)
    for message in messages.data:
        if message.role == 'assistant':
            print(message.content[0].text.value)
else:
    print(f"Erro: {run.status}")
```

### 3.1. Mem√≥ria Persistente entre Threads

Para manter mem√≥ria entre diferentes threads (conversas), voc√™ pode:

1. **Mem√≥ria Compartilhada do Assistente**: Armazenar informa√ß√µes gerais sobre o usu√°rio/empresa que s√£o compartilhadas entre todas as threads
2. **Mem√≥ria Espec√≠fica da Thread**: Armazenar informa√ß√µes aprendidas durante uma conversa espec√≠fica

```python
# Criar assistente com mem√≥ria habilitada
assistant = client.beta.assistants.create(
    name="Assistente com Mem√≥ria",
    instructions="Voc√™ √© um assistente que lembra informa√ß√µes sobre o usu√°rio.",
    model="gpt-5.1",
    reasoning_effort="medium",
    verbosity="medium"
)

# Ao usar o assistente, incluir mem√≥rias no contexto
memory_data = {
    "user_preferences": {
        "language": "pt-BR",
        "timezone": "America/Sao_Paulo"
    },
    "company_info": {
        "name": "Minha Empresa",
        "industry": "E-commerce"
    }
}

# A mem√≥ria ser√° automaticamente inclu√≠da nas mensagens quando habilitada
```

### 4. Gerenciamento de Runs

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps

```python
# Verificar status de um run
run = client.beta.threads.runs.retrieve(
    thread_id=thread.id,
    run_id=run.id
)

# Status poss√≠veis:
# - queued: Aguardando processamento
# - in_progress: Em execu√ß√£o
# - requires_action: Precisa de a√ß√£o (ex: function calling)
# - completed: Conclu√≠do com sucesso
# - failed: Falhou
# - cancelled: Cancelado
# - expired: Expirado

# Listar todos os runs de uma thread
runs = client.beta.threads.runs.list(thread_id=thread.id)

# Cancelar um run em execu√ß√£o
client.beta.threads.runs.cancel(
    thread_id=thread.id,
    run_id=run.id
)
```

### 5. Function Calling com Assistants

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/tools/function-calling

Quando um assistente precisa chamar uma fun√ß√£o, o run ter√° status `requires_action`:

```python
# Verificar se precisa executar fun√ß√µes
if run.status == 'requires_action':
    tool_calls = run.required_action.submit_tool_outputs.tool_calls
    
    tool_outputs = []
    for tool_call in tool_calls:
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)
        
        # Executar fun√ß√£o local
        if function_name == "get_product_price":
            result = get_product_price_from_db(function_args["product_id"])
        elif function_name == "update_product_price":
            result = update_product_price_in_db(
                function_args["product_id"],
                function_args["new_price"]
            )
        
        tool_outputs.append({
            "tool_call_id": tool_call.id,
            "output": json.dumps(result)
        })
    
    # Enviar resultados de volta
    run = client.beta.threads.runs.submit_tool_outputs(
        thread_id=thread.id,
        run_id=run.id,
        tool_outputs=tool_outputs
    )
    
    # Aguardar conclus√£o novamente
    run = wait_for_completion(thread.id, run.id)
```

## üõ†Ô∏è Ferramentas (Tools) para Agentes

### Code Interpreter

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/tools/code-interpreter

Permite que o agente execute c√≥digo Python:

```python
assistant = client.beta.assistants.create(
    name="Analisador de Dados",
    model="gpt-5.1",  # GPT-5.1 com melhor precis√£o e efici√™ncia
    tools=[{"type": "code_interpreter"}],
    instructions="Use Python para analisar dados e gerar gr√°ficos quando necess√°rio.",
    # GPT-5 usa reasoning_effort e verbosity
    reasoning_effort="medium",  # Racioc√≠nio m√©dio para an√°lises
    verbosity="high"  # Respostas detalhadas com gr√°ficos e explica√ß√µes
)
```

**Capacidades do Code Interpreter:**
- Executar c√≥digo Python
- Gerar gr√°ficos e visualiza√ß√µes
- Processar dados e fazer c√°lculos
- Criar arquivos tempor√°rios

### File Search

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/tools/file-search

Permite buscar informa√ß√µes em arquivos:

```python
# Primeiro, fazer upload de arquivos
file = client.files.create(
    file=open("documento.pdf", "rb"),
    purpose="assistants"
)

# Criar assistente com file_search
assistant = client.beta.assistants.create(
    name="Assistente de Documenta√ß√£o",
    model="gpt-4-turbo-preview",
    tools=[{"type": "file_search"}],
    tool_resources={
        "file_search": {
            "vector_store_ids": [vector_store.id]
        }
    },
    instructions="Use file_search para encontrar informa√ß√µes relevantes nos documentos."
)
```

### Function Calling

> **Refer√™ncia**: https://platform.openai.com/docs/assistants/tools/function-calling

Permite chamar fun√ß√µes customizadas do seu sistema:

```python
assistant = client.beta.assistants.create(
    name="Agente de Integra√ß√£o",
    model="gpt-4-turbo-preview",
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_order_status",
                "description": "Busca status de um pedido",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "order_id": {"type": "string"}
                    },
                    "required": ["order_id"]
                }
            }
        }
    ]
)
```

## üìö Modelos Dispon√≠veis

> **Refer√™ncia Completa**: https://platform.openai.com/docs/models

### Modelos Recomendados (2024-2025):

#### GPT-5 (Mais Recente):
- **gpt-5.1**: Melhor modelo para coding e tarefas agentic com racioc√≠nio configur√°vel
- **gpt-5**: Modelo anterior de racioc√≠nio inteligente para coding e tarefas agentic
- **gpt-5-pro**: Vers√£o mais inteligente e precisa do GPT-5
- **gpt-5-mini**: Vers√£o mais r√°pida e econ√¥mica para tarefas bem definidas
- **gpt-5-nano**: Vers√£o mais r√°pida e econ√¥mica do GPT-5

#### GPT-5 Codex (Otimizado para Coding):
- **gpt-5.1-codex**: Vers√£o do GPT-5.1 otimizada para coding agentic no Codex
- **gpt-5-codex**: Vers√£o do GPT-5 otimizada para coding agentic no Codex

#### GPT-4 (Anteriores):
- **gpt-4-turbo-preview**: Modelo anterior, ainda eficiente
- **gpt-4o**: Modelo otimizado para velocidade e custo
- **gpt-4o-mini**: Vers√£o menor do GPT-4o, mais econ√¥mica
- **gpt-3.5-turbo**: Mais r√°pido e econ√¥mico para tarefas simples

#### Modelos de Racioc√≠nio (SEM temperature e SEM tools):
- **o1-preview**: Modelo de racioc√≠nio avan√ßado (para an√°lises complexas)
- **o1-mini**: Vers√£o menor do o1, mais r√°pida
- **o3-preview**: Modelo de racioc√≠nio mais recente
- **o3-mini**: Vers√£o menor do o3, mais r√°pida

### üÜï GPT-5 - Caracter√≠sticas Especiais:

O **GPT-5** introduz uma arquitetura unificada com roteamento inteligente e novos par√¢metros de controle:

1. **Arquitetura Dual:**
   - **GPT-5-main**: Otimizado para consultas r√°pidas e diretas
   - **GPT-5-thinking**: Para problemas complexos que exigem racioc√≠nio aprofundado
   - Roteador autom√°tico decide qual usar baseado na complexidade da consulta

2. **Par√¢metros Especiais do GPT-5 (Diferentes dos Modelos Anteriores):**
   
   **‚ö†Ô∏è IMPORTANTE**: O GPT-5 usa par√¢metros diferentes do `temperature` tradicional:
   
   - **`reasoning_effort`** (substitui/complementa temperature):
     - Controla o n√≠vel de profundidade do racioc√≠nio antes de responder
     - Valores: `"minimal"`, `"low"`, `"medium"`, `"high"`
     - `"minimal"`: Respostas mais r√°pidas com racioc√≠nio superficial
     - `"low"`: Racioc√≠nio b√°sico, bom para tarefas simples
     - `"medium"`: Equil√≠brio entre velocidade e profundidade (padr√£o recomendado)
     - `"high"`: Racioc√≠nio profundo, ideal para problemas complexos
   
   - **`verbosity`** (controla detalhamento):
     - Controla o comprimento e n√≠vel de detalhe das respostas
     - Valores: `"low"`, `"medium"`, `"high"`
     - `"low"`: Respostas concisas e diretas
     - `"medium"`: Equil√≠brio entre concis√£o e detalhe (padr√£o)
     - `"high"`: Respostas detalhadas e elaboradas
   
   - ‚úÖ **Suporta tools** (code_interpreter, file_search, function calling)
   - ‚úÖ **Suporta max_tokens**
   - ‚úÖ **Melhor precis√£o** - 45% menos erros factuais que GPT-4o
   - ‚úÖ **Contexto expandido** - at√© 272k tokens de entrada e 128k de sa√≠da (400k total na API)

3. **Diferen√ßas dos Modelos Anteriores:**
   - **N√ÉO usa `temperature`** como par√¢metro principal (usa `reasoning_effort` e `verbosity`)
   - Racioc√≠nio integrado e autom√°tico (n√£o precisa selecionar modo manualmente)
   - Respostas mais r√°pidas e eficientes (usa menos tokens)
   - Melhor compreens√£o de contexto em conversas longas
   - Modos adapt√°veis (Mini, Nano, Thinking) para diferentes necessidades

### Sele√ß√£o de Modelo por Caso de Uso:

```python
# Para coding e tarefas agentic (RECOMENDADO - mais preciso)
model = "gpt-5.1"  # Melhor para coding e tarefas agentic

# Para coding agentic no Codex
model = "gpt-5.1-codex"  # ou "gpt-5-codex"

# Para an√°lises complexas com racioc√≠nio inteligente
model = "gpt-5"  # ou "gpt-5-pro" para mais precis√£o

# Para tarefas bem definidas (r√°pido e econ√¥mico)
model = "gpt-5-mini"  # ou "gpt-5-nano" para m√°xima velocidade

# Para an√°lises complexas com agentes (alternativa GPT-4)
model = "gpt-4-turbo-preview"

# Para tarefas simples e r√°pidas
model = "gpt-3.5-turbo"

# Para racioc√≠nio matem√°tico e l√≥gico complexo (SEM tools)
model = "o1-preview"  # ou "o3-preview" para vers√£o mais recente

# Para balance entre custo e qualidade
model = "gpt-4o"  # ou "gpt-4o-mini" para economia
```

## üîß Par√¢metros Comuns

### ‚ö†Ô∏è Diferen√ßas entre Modelos:

#### Modelos GPT-4 e Anteriores (usam `temperature`):
```python
assistant = client.beta.assistants.create(
    model="gpt-4-turbo-preview",
    temperature=0.7,  # 0.0 - 2.0
    # ...
)
```

**Temperature (0.0 - 2.0):**
- **0.0**: Respostas mais determin√≠sticas e focadas (ideal para opera√ß√µes cr√≠ticas)
- **0.3-0.5**: Para an√°lises t√©cnicas e precisas
- **0.7**: Equil√≠brio entre criatividade e precis√£o (padr√£o)
- **1.0+**: Respostas mais criativas e variadas (para conte√∫do criativo)

#### Modelos GPT-5 (usam `reasoning_effort` e `verbosity`):
```python
assistant = client.beta.assistants.create(
    model="gpt-5.1",
    reasoning_effort="medium",  # "minimal", "low", "medium", "high"
    verbosity="medium",  # "low", "medium", "high"
    # ...
)
```

**Reasoning Effort** (controla profundidade do racioc√≠nio):
- **`"minimal"`**: Respostas mais r√°pidas com racioc√≠nio superficial
  - Use para: Tarefas simples, respostas r√°pidas, opera√ß√µes b√°sicas
- **`"low"`**: Racioc√≠nio b√°sico
  - Use para: Tarefas bem definidas, consultas diretas
- **`"medium"`**: Equil√≠brio entre velocidade e profundidade (padr√£o recomendado)
  - Use para: Maioria dos casos, an√°lises gerais, tarefas moderadas
- **`"high"`**: Racioc√≠nio profundo e detalhado
  - Use para: Problemas complexos, an√°lises profundas, opera√ß√µes cr√≠ticas

**Verbosity** (controla n√≠vel de detalhamento):
- **`"low"`**: Respostas concisas e diretas
  - Use para: Opera√ß√µes precisas, respostas curtas, comandos simples
- **`"medium"`**: Equil√≠brio entre concis√£o e detalhe (padr√£o)
  - Use para: Maioria dos casos, relat√≥rios gerais
- **`"high"`**: Respostas detalhadas e elaboradas
  - Use para: An√°lises completas, explica√ß√µes detalhadas, relat√≥rios extensos

**Exemplos de Combina√ß√µes:**
```python
# Opera√ß√µes cr√≠ticas (precisas e r√°pidas)
reasoning_effort="high", verbosity="low"

# An√°lises gerais (equil√≠brio)
reasoning_effort="medium", verbosity="medium"

# Relat√≥rios detalhados (profundos e completos)
reasoning_effort="high", verbosity="high"

# Respostas r√°pidas (superficiais e concisas)
reasoning_effort="minimal", verbosity="low"
```

### Max Tokens
- Limite m√°ximo de tokens na resposta
- **4000**: Padr√£o para an√°lises longas
- **1000**: Para respostas curtas
- **8000+**: Para relat√≥rios muito detalhados
- **GPT-5**: Suporta at√© 128k tokens de sa√≠da

### Timeout
- Tempo m√°ximo de espera (em segundos)
- **180.0**: 3 minutos (padr√£o para an√°lises complexas)
- **300.0**: 5 minutos (para agentes com m√∫ltiplas etapas)

## üõ†Ô∏è Tratamento de Erros

> **Refer√™ncia**: https://platform.openai.com/docs/guides/error-codes

### Erros Comuns e Solu√ß√µes

```python
from openai import OpenAI, APIError, RateLimitError, APITimeoutError

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

try:
    response = client.chat.completions.create(...)
except RateLimitError as e:
    # Limite de requisi√ß√µes excedido
    print(f"Rate limit: {e}")
    # Implementar backoff exponencial
    time.sleep(60)
except APITimeoutError as e:
    # Timeout na requisi√ß√£o
    print(f"Timeout: {e}")
    # Tentar novamente ou aumentar timeout
except APIError as e:
    # Erro geral da API
    print(f"API Error: {e.status_code}: {e.message}")
except Exception as e:
    # Outros erros
    print(f"Erro inesperado: {e}")
```

### Retry Logic com Backoff Exponencial

```python
import time
from openai import OpenAI, RateLimitError

def call_with_retry(client, max_retries=3):
    for attempt in range(max_retries):
        try:
            return client.chat.completions.create(...)
        except RateLimitError:
            wait_time = (2 ** attempt) * 60  # 60s, 120s, 240s
            print(f"Aguardando {wait_time}s antes de tentar novamente...")
            time.sleep(wait_time)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            time.sleep(5)
    raise Exception("M√°ximo de tentativas excedido")
```

## üìä Monitoramento e Custos

> **Refer√™ncia**: https://platform.openai.com/docs/guides/rate-limits

### Verificar Uso de Tokens

```python
response = client.chat.completions.create(...)

usage = response.usage
print(f"Tokens de entrada: {usage.prompt_tokens}")
print(f"Tokens de sa√≠da: {usage.completion_tokens}")
print(f"Total: {usage.total_tokens}")

# Calcular custo aproximado (valores de exemplo)
cost_per_1k_input = 0.01  # $0.01 por 1k tokens de entrada
cost_per_1k_output = 0.03  # $0.03 por 1k tokens de sa√≠da

cost = (usage.prompt_tokens / 1000 * cost_per_1k_input) + \
       (usage.completion_tokens / 1000 * cost_per_1k_output)
print(f"Custo aproximado: ${cost:.4f}")
```

### Monitorar Runs de Agentes

```python
# Verificar status de um run
run = client.beta.threads.runs.retrieve(
    thread_id=thread_id,
    run_id=run_id
)

print(f"Status: {run.status}")
print(f"Iniciado em: {run.created_at}")
print(f"Completado em: {run.completed_at}")

# Verificar uso de tokens do run
if run.usage:
    print(f"Tokens usados: {run.usage.total_tokens}")
```

## üìñ Documenta√ß√£o Oficial Completa - Links Diretos

### Documenta√ß√£o Principal:

- **Vis√£o Geral**: https://platform.openai.com/docs/overview
- **API Reference**: https://platform.openai.com/docs/api-reference
- **Guia de In√≠cio R√°pido**: https://platform.openai.com/docs/quickstart

### Assistants API (Agentes):

- **Assistants Overview**: https://platform.openai.com/docs/assistants/overview
- **Assistants Quickstart**: https://platform.openai.com/docs/assistants/quickstart
- **Como Funciona**: https://platform.openai.com/docs/assistants/how-it-works
- **Criando Assistants**: https://platform.openai.com/docs/assistants/how-it-works/creating-assistants
- **Gerenciando Threads**: https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages
- **Runs e Run Steps**: https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps

### Ferramentas (Tools):

- **Code Interpreter**: https://platform.openai.com/docs/assistants/tools/code-interpreter
- **File Search**: https://platform.openai.com/docs/assistants/tools/file-search
- **Function Calling**: https://platform.openai.com/docs/assistants/tools/function-calling

### Modelos:

- **Modelos Dispon√≠veis**: https://platform.openai.com/docs/models
- **Guia de Modelos**: https://platform.openai.com/docs/guides/model-ratios

### Guias e Tutoriais:

- **Text Generation**: https://platform.openai.com/docs/guides/text-generation
- **Chat Completions**: https://platform.openai.com/docs/guides/text-generation/chat-completions-api
- **Function Calling Guide**: https://platform.openai.com/docs/guides/function-calling
- **Streaming**: https://platform.openai.com/docs/guides/text-generation/streaming-completions-api
- **Embeddings**: https://platform.openai.com/docs/guides/embeddings
- **Fine-tuning**: https://platform.openai.com/docs/guides/fine-tuning

### Recursos Adicionais:

- **Rate Limits**: https://platform.openai.com/docs/guides/rate-limits
- **Error Codes**: https://platform.openai.com/docs/guides/error-codes
- **Pricing**: https://openai.com/api/pricing
- **Safety Best Practices**: https://platform.openai.com/docs/guides/safety-best-practices

### SDK e Recursos:

- **SDK Python GitHub**: https://github.com/openai/openai-python
- **SDK Python Docs**: https://github.com/openai/openai-python/blob/main/README.md
- **AgentKit**: https://openai.com/agent-platform
- **DevDay 2024**: https://openai.com/devday
- **Cookbook (Exemplos)**: https://cookbook.openai.com/

## üîç Verifica√ß√£o de Instala√ß√£o

Para verificar se o SDK est√° instalado corretamente:

```bash
docker compose exec api python -c "from openai import OpenAI; print('‚úÖ OpenAI SDK instalado com sucesso')"
```

Para testar a cria√ß√£o de um assistente:

```bash
docker compose exec api python -c "
from openai import OpenAI
import os
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
assistant = client.beta.assistants.create(
    name='Test Assistant',
    instructions='You are a helpful assistant.',
    model='gpt-4-turbo-preview'
)
print(f'‚úÖ Assistente criado: {assistant.id}')
"
```

## ‚ö†Ô∏è Notas Importantes

### Custos
- Cada chamada consome tokens. Monitore o uso na dashboard: https://platform.openai.com/usage
- Modelos diferentes t√™m custos diferentes (GPT-4 √© mais caro que GPT-3.5)
- Assistants API pode ter custos adicionais para ferramentas como code interpreter
- **Pricing**: https://openai.com/api/pricing

### Rate Limits
- A API tem limites de requisi√ß√µes por minuto/hora
- Implemente retry logic com backoff exponencial
- Considere usar filas para processar requisi√ß√µes em lote
- **Rate Limits Guide**: https://platform.openai.com/docs/guides/rate-limits

### Seguran√ßa
- **NUNCA** commite a chave da API no c√≥digo
- Use sempre vari√°veis de ambiente
- Revogue chaves comprometidas imediatamente
- Use chaves diferentes para desenvolvimento e produ√ß√£o
- **Safety Best Practices**: https://platform.openai.com/docs/guides/safety-best-practices

### Modelos
- Alguns modelos podem estar em preview e sujeitos a mudan√ßas
- Verifique a documenta√ß√£o para modelos mais recentes: https://platform.openai.com/docs/models
- Modelos preview podem ter limita√ß√µes ou custos diferentes

### Assistants API
- Assistants mant√™m estado e podem acumular custos
- Delete assistants n√£o utilizados para economizar
- Threads tamb√©m ocupam espa√ßo, limpe threads antigas periodicamente
- **Assistants Overview**: https://platform.openai.com/docs/assistants/overview

## üöÄ Pr√≥ximos Passos

1. **Acesse a documenta√ß√£o oficial**: https://platform.openai.com/docs/overview
2. **Configure a `OPENAI_API_KEY`** no arquivo `.env`
3. **Teste Chat Completions** b√°sico para verificar conex√£o
4. **Crie seu primeiro Assistente** usando os exemplos acima
5. **Implemente Function Calling** para integrar com suas APIs
6. **Monitore custos** na dashboard da OpenAI
7. **Otimize modelos** escolhendo o mais adequado para cada caso

## üìù Exemplo Completo: Sistema de An√°lise com Agente

```python
import os
import time
import json
from typing import Dict
from openai import OpenAI
from sqlalchemy.orm import Session

class MLProductAnalysisAgent:
    """Agente completo para an√°lise de produtos do Mercado Livre"""
    
    def __init__(self, db: Session):
        self.db = db
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.assistant_id = self._get_or_create_assistant()
    
    def _get_or_create_assistant(self) -> str:
        """Obt√©m ou cria o assistente"""
        # Em produ√ß√£o, salvar assistant_id no banco de dados
            assistant = self.client.beta.assistants.create(
                name="Analisador de Produtos ML",
                instructions="""Voc√™ √© um especialista em an√°lise de produtos para marketplaces.
                
                Analise produtos do Mercado Livre fornecendo:
                1. An√°lise de pre√ßo e competitividade
                2. Sugest√µes de SEO
                3. An√°lise de margem e rentabilidade
                4. Recomenda√ß√µes priorizadas""",
                model="gpt-5.1",  # GPT-5.1 com melhor precis√£o e racioc√≠nio autom√°tico
                tools=[{"type": "code_interpreter"}],
                # GPT-5 usa reasoning_effort e verbosity ao inv√©s de temperature
                reasoning_effort="high",  # Racioc√≠nio profundo para an√°lises complexas
                verbosity="high"  # Respostas detalhadas com recomenda√ß√µes completas
            )
        return assistant.id
    
    def analyze_product(self, product_id: int, company_id: int) -> Dict:
        """Analisa um produto completo"""
        # Buscar dados do produto do banco
        from app.models.saas_models import MLProduct
        product = self.db.query(MLProduct).filter(
            MLProduct.id == product_id,
            MLProduct.company_id == company_id
        ).first()
        
        if not product:
            return {"success": False, "error": "Produto n√£o encontrado"}
        
        # Preparar dados
        product_data = {
            "id": product.ml_item_id,
            "title": product.title,
            "price": float(product.price) if product.price else 0,
            "description": product.description,
            "category": product.category_name,
            "stock": product.available_quantity,
            "sold": product.sold_quantity
        }
        
        # Criar thread e analisar
        thread = self.client.beta.threads.create()
        
        self.client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=f"Analise este produto: {json.dumps(product_data, indent=2)}"
        )
        
        run = self.client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=self.assistant_id
        )
        
        # Aguardar conclus√£o
        run = self._wait_for_run(thread.id, run.id)
        
        if run.status == 'completed':
            messages = self.client.beta.threads.messages.list(
                thread_id=thread.id,
                order="desc",
                limit=1
            )
            
            if messages.data:
                analysis = messages.data[0].content[0].text.value
                return {
                    "success": True,
                    "analysis": analysis,
                    "thread_id": thread.id
                }
        
        return {"success": False, "error": f"Status: {run.status}"}
    
    def _wait_for_run(self, thread_id: str, run_id: str, timeout: int = 300):
        """Aguarda conclus√£o de um run com timeout"""
        start = time.time()
        while time.time() - start < timeout:
            run = self.client.beta.threads.runs.retrieve(
                thread_id=thread_id,
                run_id=run_id
            )
            if run.status in ['completed', 'failed', 'cancelled']:
                return run
            time.sleep(1)
        raise TimeoutError("Run n√£o completou a tempo")
```

## üéØ Casos de Uso Pr√°ticos

### 1. An√°lise Autom√°tica de Produtos
- Criar agente que analisa produtos automaticamente
- Gerar relat√≥rios de otimiza√ß√£o
- Sugerir melhorias de pre√ßo e SEO

### 2. Suporte ao Cliente
- Agente que responde perguntas sobre pedidos
- Consulta status de envio
- Resolve problemas comuns

### 3. An√°lise de Concorr√™ncia
- Comparar pre√ßos com concorrentes
- Identificar oportunidades de mercado
- Sugerir estrat√©gias de precifica√ß√£o

### 4. Gera√ß√£o de Conte√∫do
- Criar descri√ß√µes otimizadas de produtos
- Gerar t√≠tulos para SEO
- Criar conte√∫do de marketing

## üìû Suporte e Recursos

- **Documenta√ß√£o**: https://platform.openai.com/docs
- **F√≥rum da Comunidade**: https://community.openai.com/
- **Status da API**: https://status.openai.com/
- **Suporte**: https://help.openai.com/
- **Cookbook (Exemplos)**: https://cookbook.openai.com/

---

**üìå IMPORTANTE**: Para informa√ß√µes mais atualizadas e detalhadas, sempre consulte a documenta√ß√£o oficial em: **https://platform.openai.com/docs/overview**

**√öltima atualiza√ß√£o**: Dezembro 2024  
**Vers√£o do SDK**: 1.12.0  
**Status**: ‚úÖ Pronto para uso com Assistants API
